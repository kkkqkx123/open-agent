# 异步工作流实现分析

## 概述
当前异步工作流实现采用分层架构，从上层的 `GraphWorkflow` 到中层的 `WorkflowInstance`，再到底层的 LangGraph 图执行引擎，形成完整的异步执行链。

---

## 整体架构

```
GraphWorkflow (表现层)
    ↓
WorkflowInstance (应用层)
    ↓
LangGraph Graph (基础设施层)
    ↓
AsyncExecutor / LangGraph 原生异步 (执行引擎)
```

---

## 第一层：GraphWorkflow（表现层）

### 文件位置
`src/application/workflow/graph_workflow.py`

### 异步方法

#### 1. `run_async()` - 异步运行（单次执行）
```python
async def run_async(
    self, 
    initial_data: Optional[Dict[str, Any]] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> Dict[str, Any]:
    """异步运行工作流"""
    try:
        run_config = {**(config or {}), **kwargs}
        return await self.instance.run_async(initial_data, run_config)
    except Exception as e:
        raise GraphWorkflowExecutionError(f"工作流异步执行失败: {e}") from e
```

**特点：**
- 直接委托给 `WorkflowInstance.run_async()`
- 返回最终执行结果（Dict[str, Any]）
- 异常包装为 `GraphWorkflowExecutionError`

#### 2. `stream_async()` - 异步流式执行（增量返回）
```python
async def stream_async(
    self, 
    initial_data: Optional[Dict[str, Any]] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> AsyncIterator[Dict[str, Any]]:
    """异步流式运行工作流"""
    try:
        run_config = {**(config or {}), **kwargs}
        async for chunk in self.instance.stream_async(initial_data, run_config):
            yield chunk
    except Exception as e:
        raise GraphWorkflowExecutionError(f"工作流异步流式执行失败: {e}") from e
```

**特点：**
- 返回异步生成器 `AsyncIterator[Dict[str, Any]]`
- 支持实时获取中间执行结果
- 保持与同步 `stream()` 的接口一致性

---

## 第二层：WorkflowInstance（应用层）

### 文件位置
`src/application/workflow/universal_loader.py`

### 核心职责
- 管理工作流图和配置
- 处理初始状态创建
- 路由到不同的执行方式

### 异步方法实现

#### 1. `run_async()` - 异步执行逻辑
```python
async def run_async(
    self, 
    initial_data: Optional[Dict[str, Any]] = None,
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    # 创建初始状态
    initial_state = self._create_initial_state(initial_data)
    run_config = config or {}
    
    # 设置递归限制（LangGraph参数）
    if "recursion_limit" not in run_config:
        run_config["recursion_limit"] = self.config.additional_config.get("recursion_limit", 10)
    
    try:
        logger.info(f"开始异步执行工作流: {self.config.name}")
        
        # 关键：检查图是否支持异步
        if hasattr(self.graph, 'ainvoke'):
            result = await self.graph.ainvoke(initial_state, config=run_config)
        else:
            # 降级：如果不支持异步，使用同步方式
            result = self.graph.invoke(initial_state, config=run_config)
        
        logger.info(f"工作流异步执行完成: {self.config.name}")
        return result
        
    except Exception as e:
        logger.error(f"工作流异步执行失败: {self.config.name}, 错误: {e}")
        raise UniversalLoaderError(f"工作流异步执行失败: {e}") from e
```

**执行流程：**
```
run_async()
  ├─ _create_initial_state() - 初始化状态
  ├─ 检查 graph.ainvoke 存在性
  ├─ 存在 → await graph.ainvoke()  [LangGraph 原生异步]
  └─ 不存在 → graph.invoke()      [降级到同步]
```

**关键特性：**
- **动态能力检测**：通过 `hasattr()` 检查图是否支持异步
- **优雅降级**：不支持异步时自动降级到同步执行
- **递归限制**：设置 LangGraph 的递归限制参数（默认10）

#### 2. `stream_async()` - 异步流式执行逻辑
```python
async def stream_async(
    self, 
    initial_data: Optional[Dict[str, Any]] = None,
    config: Optional[Dict[str, Any]] = None
) -> AsyncIterator[Dict[str, Any]]:
    initial_state = self._create_initial_state(initial_data)
    run_config = config or {}
    
    try:
        logger.info(f"开始异步流式执行工作流: {self.config.name}")
        
        # 关键：优先使用异步流式执行
        if hasattr(self.graph, 'astream'):
            async for chunk in self.graph.astream(initial_state, config=run_config):
                yield chunk
        else:
            # 降级：使用同步流式执行
            for chunk in self.stream(initial_data, config):
                yield chunk
        
        logger.info(f"工作流异步流式执行完成: {self.config.name}")
        
    except Exception as e:
        logger.error(f"工作流异步流式执行失败: {self.config.name}, 错误: {e}")
        raise UniversalLoaderError(f"工作流异步流式执行失败: {e}") from e
```

**执行流程：**
```
stream_async()
  ├─ _create_initial_state() - 初始化状态
  ├─ 检查 graph.astream 存在性
  ├─ 存在 → async for graph.astream()  [LangGraph 原生异步流]
  └─ 不存在 → for self.stream()        [降级到同步流]
```

**关键特性：**
- **异步生成器模式**：使用 `async for` 遍历异步迭代器
- **实时流式**：支持实时获取中间执行结果
- **多层降级**：支持异步流 → 同步流的降级

#### 3. `_create_initial_state()` - 状态初始化
```python
def _create_initial_state(self, initial_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """创建初始状态"""
    return self._template_manager.create_state_from_config(self.config, initial_data)
```

**作用：**
- 使用状态模板管理器根据配置创建初始状态
- 合并用户提供的初始数据
- 确保状态符合工作流定义的 schema

---

## 第三层：LangGraph 执行引擎

### 文件位置
`src/infrastructure/graph/` - 包含多个构建器和执行器

### LangGraph 原生异步支持

LangGraph 提供原生异步方法：
- **`ainvoke()`** - 异步调用，返回最终状态
- **`astream()`** - 异步流式调用，逐步返回中间状态
- **`astream_log()`** - 异步流式调用（带详细日志）

### WorkflowInstance 对 LangGraph 的适配

#### 适配机制
```python
# 方式1：直接使用原生异步
if hasattr(self.graph, 'ainvoke'):
    result = await self.graph.ainvoke(state, config=config)

# 方式2：检查流式异步
if hasattr(self.graph, 'astream'):
    async for chunk in self.graph.astream(state, config=config):
        yield chunk
```

#### 配置参数传递
```python
run_config = {
    "recursion_limit": 10,  # 从配置读取或使用默认值
    # 其他LangGraph配置
}

result = await self.graph.ainvoke(initial_state, config=run_config)
```

---

## 异步执行器（补充层）

### 文件位置
`src/infrastructure/graph/async_executor.py`

### 两个关键类

#### 1. AsyncNodeExecutor - 异步节点执行器
负责单个节点的异步执行

**执行策略：**
```python
async def execute(self, state: WorkflowState, config: Dict[str, Any]) -> WorkflowState:
    # 优先级：异步节点 > 同步节点（线程池）
    
    if hasattr(node_instance, 'execute_async'):
        # 1. 节点本身支持异步
        result = await node_instance.execute_async(state, config)
    else:
        # 2. 同步节点在线程池中运行
        loop = asyncio.get_running_loop()
        result = await loop.run_in_executor(
            None, node_instance.execute, state, config
        )
```

**内置节点异步执行：**
- `_execute_llm_node_async()` - 调用 LLM 客户端异步生成
- `_execute_tool_node_async()` - 并行执行多个工具调用
- `_execute_analysis_node_async()` - 异步分析
- `_execute_condition_node_async()` - 异步条件判断

#### 2. AsyncWorkflowExecutor - 异步工作流执行器
负责整个工作流的异步执行协调

```python
async def execute(self, graph: Any, initial_state: WorkflowState, **kwargs) -> WorkflowState:
    if hasattr(graph, 'ainvoke') and callable(getattr(graph, 'ainvoke')):
        # 方式1：直接异步invoke
        result = await graph.ainvoke(initial_state, **kwargs)
    elif hasattr(graph, 'astream') and callable(getattr(graph, 'astream')):
        # 方式2：异步流式（累积最终结果）
        final_state = initial_state
        async for chunk in graph.astream(initial_state, **kwargs):
            final_state = chunk
    else:
        # 方式3：降级到线程池中执行同步invoke
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, graph.invoke, initial_state, kwargs)
```

---

## 完整执行链示例

### 异步执行（单次）
```
用户代码
  ↓
GraphWorkflow.run_async(initial_data)
  ↓
WorkflowInstance.run_async(initial_data, config)
  ├─ _create_initial_state(initial_data)
  └─ await self.graph.ainvoke(initial_state, config)
  ↓
LangGraph StateGraph.ainvoke()
  ├─ 遍历节点执行
  └─ 返回最终状态
  ↓
完整结果 Dict[str, Any]
```

### 异步流式执行
```
用户代码
  ↓
GraphWorkflow.stream_async(initial_data)
  ├─ 返回异步生成器
  ↓
WorkflowInstance.stream_async(initial_data, config)
  ├─ _create_initial_state(initial_data)
  └─ async for chunk in self.graph.astream(initial_state, config)
  ├─ yield chunk (中间结果1)
  ├─ yield chunk (中间结果2)
  └─ yield chunk (最终结果)
  ↓
用户逐个接收中间结果
```

---

## 异步特性对比

| 特性 | run_async | stream_async |
|------|-----------|--------------|
| 返回值 | Dict[str, Any] | AsyncIterator[Dict[str, Any]] |
| 中间结果 | ❌ 不可见 | ✅ 逐步返回 |
| 性能 | 高效 | 更细粒度控制 |
| 使用场景 | 完整执行 | 实时反馈/可中断 |
| 生成方式 | await | async for / async generator |

---

## 降级策略

系统采用**多层降级**确保兼容性：

```
优先级链：
1. LangGraph.ainvoke()        [最优 - 原生异步]
   ↓ (如果不存在)
2. LangGraph.invoke()         [次优 - 同步执行]

对于流式：
1. LangGraph.astream()        [最优 - 异步流]
   ↓ (如果不存在)
2. 同步 stream() 方法         [次优 - 同步流]
   ↓ (如果不存在)
3. LangGraph.invoke()         [最后手段]
```

---

## 关键优化点

### 1. 动态能力检测
```python
if hasattr(self.graph, 'ainvoke'):
    # 运行时检测，无需预先配置
```

### 2. 优雅降级
```python
# 自动降级，无需用户干预
if hasattr(graph, 'ainvoke'):
    result = await graph.ainvoke(...)
else:
    result = graph.invoke(...)  # 同步退路
```

### 3. 线程池混合执行
```python
# 同步节点在线程池中异步执行
loop = asyncio.get_running_loop()
result = await loop.run_in_executor(None, sync_func, args)
```

### 4. 并行工具执行
```python
# 多个工具调用并行执行
tool_results = await self._tool_executor.execute_parallel_async(tool_calls)
```

### 5. 递归限制
```python
run_config = {
    "recursion_limit": 10,  # 防止无限循环
}
```

---

## 错误处理

### 异常链
```
用户异常
  ↓
UniversalLoaderError (应用层)
  ↓
GraphWorkflowExecutionError (表现层)
```

### 错误日志
- 结构化日志：`logger.error()` 记录完整上下文
- 异常链保留：`raise ... from e` 保留原始异常
- 日志级别：
  - INFO: 执行开始/完成
  - WARNING: 能力降级
  - ERROR: 执行失败

---

## 使用示例

### 基本异步执行
```python
workflow = GraphWorkflow(config)

# 单次执行
result = await workflow.run_async({"input": "data"})

# 流式执行
async for chunk in workflow.stream_async({"input": "data"}):
    print(f"中间结果: {chunk}")
```

### 在 FastAPI 中使用
```python
@app.post("/workflow/async")
async def run_workflow_async(request: WorkflowRequest):
    workflow = GraphWorkflow(config)
    result = await workflow.run_async(request.data)
    return result

@app.post("/workflow/stream")
async def stream_workflow(request: WorkflowRequest):
    workflow = GraphWorkflow(config)
    
    async def stream_generator():
        async for chunk in workflow.stream_async(request.data):
            yield f"data: {json.dumps(chunk)}\n\n"
    
    return StreamingResponse(stream_generator(), media_type="text/event-stream")
```

---

## 设计模式总结

| 模式 | 实现位置 | 用途 |
|------|--------|------|
| **适配器模式** | WorkflowInstance | 适配 LangGraph 接口 |
| **降级模式** | hasattr 检查 | 兼容不同图实现 |
| **委托模式** | GraphWorkflow → WorkflowInstance | 职责分离 |
| **生成器模式** | stream_async | 异步迭代 |
| **线程池适配** | AsyncNodeExecutor | 同步→异步转换 |

---

## 性能考虑

1. **异步 vs 同步**
   - 异步版本避免线程开销
   - I/O密集型任务性能提升明显
   - CPU密集型任务性能相近

2. **流式 vs 单次**
   - 流式版本实时反馈，可中断
   - 单次版本更简洁，吞吐量可能更高

3. **递归限制**
   - 默认10，防止无限循环
   - 可通过配置调整，需权衡内存

---

## 总结

当前异步工作流实现采用：
1. **分层设计**：表现层→应用层→基础设施层
2. **能力检测**：运行时动态检查异步支持
3. **优雅降级**：不支持异步自动降级到同步
4. **混合执行**：异步调用 + 线程池 + 并行工具
5. **完整异常链**：保留原始异常信息便于调试

这种设计确保了灵活性、兼容性和可维护性。
