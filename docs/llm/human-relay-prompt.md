我希望实现一个新的llm：human-relay。该llm主要是为了使用web端的llm，而非使用api。该llm分为2种模式：单轮对话(human-relay-s)和多轮对话(human-relay-m)，前者每次调用时直接在前端给出完整提示词，并等待用户输入web llm的回复。后者则使用多轮对话的处理方式，在前端给出增量提示词，并等待用户输入web llm的回复。假定web llm保留了历史对话。目前该项目的前端展现包括tui和web前端。由于这些前端还未完善，前端交互形式仅给出大致的方案即可。

分析该如何实现并无缝集成到现有项目中。