"""å°†åŸºäºçŠ¶æ€æœºçš„å·¥ä½œæµé…ç½®è½¬æ¢ä¸ºåŸºäºå›¾çš„é…ç½®æ ¼å¼"""
"""ä¾‹å¦‚æŠŠconfigs/workflows/ultra_thinking_workflow.yamlæ”¹ä¸ºconfigs/workflows/ultra_thinking_workflow_convert.yaml"""

import yaml
import os
from typing import Dict, Any, List

def convert_states_to_graph(config_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    å°†åŸºäºçŠ¶æ€æœºçš„é…ç½®è½¬æ¢ä¸ºåŸºäºå›¾çš„é…ç½®
    
    Args:
        config_data: åŸå§‹é…ç½®æ•°æ®ï¼ˆåŒ…å«stateså­—æ®µï¼‰
        
    Returns:
        è½¬æ¢åçš„é…ç½®æ•°æ®ï¼ˆåŒ…å«nodeså’Œedgeså­—æ®µï¼‰
    """
    if 'states' not in config_data:
        raise ValueError("é…ç½®æ•°æ®ä¸åŒ…å«stateså­—æ®µï¼Œæ— æ³•è½¬æ¢")
    
    # åˆ›å»ºæ–°çš„é…ç½®ç»“æ„
    converted_config = {
        'name': config_data.get('name', 'converted_workflow'),
        'description': config_data.get('description', 'è½¬æ¢åçš„å·¥ä½œæµ'),
        'version': config_data.get('version', '1.0.0'),
        'config_type': 'workflow',
        'workflow_name': config_data.get('name', 'converted_workflow'),
        'max_iterations': config_data.get('max_iterations', 10),
        'timeout': config_data.get('timeout', 300),
        'nodes': {},
        'edges': [],
        'state_schema': config_data.get('state_schema', {
            'name': 'WorkflowState',
            'fields': {
                'messages': {
                    'type': 'List[dict]',
                    'default': [],
                    'reducer': 'extend',
                    'description': 'æ¶ˆæ¯åˆ—è¡¨'
                },
                'input': {
                    'type': 'str',
                    'default': '',
                    'description': 'è¾“å…¥æ–‡æœ¬'
                },
                'output': {
                    'type': 'str',
                    'default': '',
                    'description': 'è¾“å‡ºæ–‡æœ¬'
                },
                'errors': {
                    'type': 'List[str]',
                    'default': [],
                    'reducer': 'extend',
                    'description': 'é”™è¯¯åˆ—è¡¨'
                }
            }
        })
    }
    
    # è½¬æ¢çŠ¶æ€ä¸ºèŠ‚ç‚¹
    states = config_data['states']
    entry_point = None
    
    for state_name, state_config in states.items():
        # ç¡®å®šèŠ‚ç‚¹ç±»å‹
        node_type = state_config.get('type', 'process')
        
        # åˆ›å»ºèŠ‚ç‚¹é…ç½®
        node_config = {
            'function': f"{state_name}_node",
            'description': state_config.get('description', f'{state_name}èŠ‚ç‚¹'),
            'config': state_config.get('config', {})
        }
        
        # æ ¹æ®çŠ¶æ€ç±»å‹è®¾ç½®ä¸åŒçš„èŠ‚ç‚¹é…ç½®
        if node_type == 'start':
            node_config['function'] = 'start_node'
            entry_point = state_name
        elif node_type == 'end':
            node_config['function'] = 'end_node'
        elif node_type == 'llm_node':
            node_config['function'] = 'llm_node'
        elif node_type == 'deep_thinking_node':
            node_config['function'] = 'deep_thinking_node'
        elif node_type == 'analysis_node':
            node_config['function'] = 'analysis_node'
        elif node_type == 'parallel_node':
            node_config['function'] = 'parallel_node'
        elif node_type == 'agent_config_node':
            node_config['function'] = 'agent_config_node'
        elif node_type == 'collaboration_node':
            node_config['function'] = 'collaboration_node'
        
        converted_config['nodes'][state_name] = node_config
    
    # è½¬æ¢çŠ¶æ€è½¬ç§»ä¸ºè¾¹
    for state_name, state_config in states.items():
        transitions = state_config.get('transitions', [])
        
        for transition in transitions:
            target_state = transition.get('target')
            condition = transition.get('condition', 'always')
            description = transition.get('description', f'ä»{state_name}åˆ°{target_state}')
            
            if target_state in states:
                # åˆ›å»ºè¾¹é…ç½®
                edge_config = {
                    'from': state_name,
                    'to': target_state,
                    'type': 'conditional' if condition != 'always' else 'simple',
                    'description': description
                }
                
                # æ·»åŠ æ¡ä»¶é…ç½®
                if condition != 'always':
                    edge_config['condition'] = condition
                
                converted_config['edges'].append(edge_config)
    
    # è®¾ç½®å…¥å£ç‚¹
    if entry_point:
        converted_config['entry_point'] = entry_point
    else:
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„startçŠ¶æ€ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªçŠ¶æ€ä½œä¸ºå…¥å£ç‚¹
        first_state = list(states.keys())[0]
        converted_config['entry_point'] = first_state
    
    # ä¿ç•™åŸå§‹é…ç½®çš„å…ƒæ•°æ®
    if 'metadata' in config_data:
        converted_config['metadata'] = config_data['metadata']
    
    # ä¿ç•™è¾“å…¥æ¨¡å¼
    if 'input_schema' in config_data:
        converted_config['input_schema'] = config_data['input_schema']
    
    # ä¿ç•™é”™è¯¯å¤„ç†é…ç½®
    if 'error_handling' in config_data:
        converted_config['error_handling'] = config_data['error_handling']
    
    # ä¿ç•™ç›‘æ§é…ç½®
    if 'monitoring' in config_data:
        converted_config['monitoring'] = config_data['monitoring']
    
    return converted_config

def convert_workflow_file(input_file: str, output_file: str | None = None) -> bool:
    """
    è½¬æ¢å·¥ä½œæµé…ç½®æ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶åŠ _convertedåç¼€ï¼‰
        
    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        print(f"ğŸ“– è¯»å–é…ç½®æ–‡ä»¶: {input_file}")
        print(f"   å·¥ä½œæµåç§°: {config_data.get('name', 'æœªå‘½å')}")
        print(f"   çŠ¶æ€æ•°é‡: {len(config_data.get('states', {}))}")
        
        # è½¬æ¢é…ç½®
        converted_config = convert_states_to_graph(config_data)
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_file is None:
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}_converted.yaml"
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(converted_config, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        print(f"âœ… è½¬æ¢å®Œæˆ: {output_file}")
        print(f"   èŠ‚ç‚¹æ•°é‡: {len(converted_config['nodes'])}")
        print(f"   è¾¹æ•°é‡: {len(converted_config['edges'])}")
        print(f"   å…¥å£èŠ‚ç‚¹: {converted_config.get('entry_point', 'æœªè®¾ç½®')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return False

def validate_converted_config(config_file: str) -> bool:
    """
    éªŒè¯è½¬æ¢åçš„é…ç½®æ–‡ä»¶
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        bool: éªŒè¯æ˜¯å¦é€šè¿‡
    """
    try:
        # å¯¼å…¥éªŒè¯å™¨ï¼ˆéœ€è¦ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
        import sys
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        
        from src.core.workflow.core.validator import WorkflowValidator
        
        validator = WorkflowValidator()
        issues = validator.validate_config_file(config_file)
        
        print(f"\nğŸ” éªŒè¯è½¬æ¢åçš„é…ç½®æ–‡ä»¶: {config_file}")
        
        if issues:
            error_count = sum(1 for issue in issues if issue.severity.value == "error")
            warning_count = sum(1 for issue in issues if issue.severity.value == "warning")
            
            print(f"   å‘ç° {len(issues)} ä¸ªé—®é¢˜ (é”™è¯¯: {error_count}, è­¦å‘Š: {warning_count})")
            
            for i, issue in enumerate(issues, 1):
                print(f"   {i}. [{issue.severity.value}] {issue.message}")
                if issue.suggestion:
                    print(f"      å»ºè®®: {issue.suggestion}")
            
            return error_count == 0
        else:
            print("   âœ… éªŒè¯é€šè¿‡ï¼Œæ— é—®é¢˜")
            return True
            
    except Exception as e:
        print(f"   âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å·¥ä½œæµé…ç½®æ ¼å¼è½¬æ¢å·¥å…·")
    print("=" * 60)
    
    # è½¬æ¢Deep Thinkingå·¥ä½œæµ
    print("\n1. è½¬æ¢Deep Thinkingå·¥ä½œæµé…ç½®:")
    deep_thinking_input = "configs/workflows/deep_thinking_workflow.yaml"
    deep_thinking_output = "configs/workflows/deep_thinking_workflow_converted.yaml"
    
    deep_success = convert_workflow_file(deep_thinking_input, deep_thinking_output)
    
    if deep_success:
        validate_converted_config(deep_thinking_output)
    
    # è½¬æ¢Ultra Thinkingå·¥ä½œæµ
    print("\n2. è½¬æ¢Ultra Thinkingå·¥ä½œæµé…ç½®:")
    ultra_thinking_input = "configs/workflows/ultra_thinking_workflow.yaml"
    ultra_thinking_output = "configs/workflows/ultra_thinking_workflow_converted.yaml"
    
    ultra_success = convert_workflow_file(ultra_thinking_input, ultra_thinking_output)
    
    if ultra_success:
        validate_converted_config(ultra_thinking_output)
    
    print("\n" + "=" * 60)
    print("è½¬æ¢ç»“æœæ±‡æ€»:")
    print(f"Deep Thinking: {'âœ… æˆåŠŸ' if deep_success else 'âŒ å¤±è´¥'}")
    print(f"Ultra Thinking: {'âœ… æˆåŠŸ' if ultra_success else 'âŒ å¤±è´¥'}")
    
    if deep_success and ultra_success:
        print("\nğŸ‰ æ‰€æœ‰å·¥ä½œæµé…ç½®è½¬æ¢å®Œæˆï¼")
        print("è½¬æ¢åçš„é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°configs/workflows/ç›®å½•")
        print("è¿™äº›æ–‡ä»¶ç°åœ¨å¯ä»¥è¢«å·¥ä½œæµç³»ç»Ÿæ­£ç¡®è§£æ")
    else:
        print("\nâš ï¸  éƒ¨åˆ†è½¬æ¢å¤±è´¥ï¼Œéœ€è¦æ‰‹åŠ¨æ£€æŸ¥é…ç½®")

if __name__ == "__main__":
    main()