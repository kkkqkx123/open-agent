#!/usr/bin/env python3
"""éªŒè¯YAMLé…ç½®æ–‡ä»¶çš„å‚æ•°æ”¯æŒ"""

import yaml
import os
from pathlib import Path

def validate_yaml_files():
    """éªŒè¯YAMLé…ç½®æ–‡ä»¶"""
    print("éªŒè¯YAMLé…ç½®æ–‡ä»¶...")
    
    config_files = [
        "configs/llms/openai-gpt4.yaml",
        "configs/llms/anthropic-claude.yaml", 
        "configs/llms/gemini-pro.yaml",
        "configs/llms/mock.yaml",
        "configs/llms/_group.yaml"
    ]
    
    all_valid = True
    
    for config_file in config_files:
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            print(f"âœ“ {config_file}")
            print(f"  - æ¨¡å‹ç±»å‹: {config.get('model_type', 'N/A')}")
            print(f"  - æ¨¡å‹åç§°: {config.get('model_name', 'N/A')}")
            
            if 'parameters' in config:
                params = config['parameters']
                print(f"  - å‚æ•°æ•°é‡: {len(params)}")
                
                # æ£€æŸ¥å…³é”®å‚æ•°
                key_params = ['temperature', 'max_tokens', 'top_p']
                for param in key_params:
                    if param in params:
                        print(f"  - {param}: {params[param]}")
                
                # æ£€æŸ¥é«˜çº§å‚æ•°
                advanced_params = []
                if config.get('model_type') == 'openai':
                    advanced_params = ['max_completion_tokens', 'frequency_penalty', 'presence_penalty', 
                                     'top_logprobs', 'tool_choice', 'response_format', 'service_tier',
                                     'safety_identifier', 'store', 'reasoning', 'verbosity']
                elif config.get('model_type') == 'anthropic':
                    advanced_params = ['top_k', 'stop_sequences', 'system', 'thinking_config']
                elif config.get('model_type') == 'gemini':
                    advanced_params = ['max_output_tokens', 'top_k', 'stop_sequences', 
                                     'candidate_count', 'system_instruction', 'response_mime_type']
                elif config.get('model_type') == 'mock':
                    advanced_params = ['response_delay', 'error_rate', 'error_types']
                
                for param in advanced_params:
                    if param in params:
                        print(f"  - {param}: {params[param]}")
            
            print()
            
        except Exception as e:
            print(f"âœ— {config_file}: {e}")
            all_valid = False
    
    return all_valid

def summarize_improvements():
    """æ€»ç»“æ”¹è¿›å†…å®¹"""
    print("å‚æ•°æ”¯æŒæ”¹è¿›æ€»ç»“:")
    print("=" * 50)
    
    improvements = {
        "OpenAI": [
            "max_completion_tokens - æœ€å¤§å®Œæˆtokenæ•°",
            "frequency_penalty - é¢‘ç‡æƒ©ç½š",
            "presence_penalty - å­˜åœ¨æƒ©ç½š", 
            "top_logprobs - å¯¹æ•°æ¦‚ç‡è¿”å›",
            "tool_choice - å·¥å…·é€‰æ‹©",
            "response_format - å“åº”æ ¼å¼",
            "service_tier - æœåŠ¡å±‚",
            "safety_identifier - å®‰å…¨æ ‡è¯†ç¬¦",
            "store - å­˜å‚¨é€‰é¡¹",
            "reasoning - æ¨ç†é…ç½®",
            "verbosity - è¯¦ç»†ç¨‹åº¦",
            "web_search_options - ç½‘ç»œæœç´¢",
            "seed - éšæœºç§å­",
            "user - ç”¨æˆ·æ ‡è¯†"
        ],
        "Anthropic": [
            "top_k - Top-Ké‡‡æ ·",
            "stop_sequences - åœæ­¢åºåˆ—",
            "system - ç³»ç»ŸæŒ‡ä»¤",
            "thinking_config - æ€è€ƒé…ç½®",
            "response_format - å“åº”æ ¼å¼",
            "metadata - å…ƒæ•°æ®",
            "user - ç”¨æˆ·æ ‡è¯†"
        ],
        "Gemini": [
            "max_output_tokens - æœ€å¤§è¾“å‡ºtoken",
            "top_k - Top-Ké‡‡æ ·",
            "stop_sequences - åœæ­¢åºåˆ—",
            "candidate_count - å€™é€‰æ•°é‡",
            "system_instruction - ç³»ç»ŸæŒ‡ä»¤",
            "response_mime_type - å“åº”MIMEç±»å‹",
            "thinking_config - æ€è€ƒé…ç½®",
            "safety_settings - å®‰å…¨è®¾ç½®",
            "user - ç”¨æˆ·æ ‡è¯†"
        ],
        "Mock": [
            "æ”¯æŒæ‰€æœ‰å‚æ•°çš„æ¨¡æ‹Ÿ",
            "response_delay - å“åº”å»¶è¿Ÿ",
            "error_rate - é”™è¯¯ç‡",
            "error_types - é”™è¯¯ç±»å‹"
        ]
    }
    
    for provider, params in improvements.items():
        print(f"\n{provider} æ–°å¢å‚æ•°:")
        for param in params:
            print(f"  âœ“ {param}")
    
    print(f"\næ€»è®¡æ–°å¢å‚æ•°: {sum(len(params) for params in improvements.values())}")

def main():
    """ä¸»å‡½æ•°"""
    print("LLMå‚æ•°æ”¯æŒéªŒè¯æŠ¥å‘Š")
    print("=" * 50)
    
    # éªŒè¯YAMLæ–‡ä»¶
    if validate_yaml_files():
        print("âœ“ æ‰€æœ‰é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        
        # æ€»ç»“æ”¹è¿›
        summarize_improvements()
        
        print("\nğŸ‰ å‚æ•°æ”¯æŒæ›´æ–°å®Œæˆï¼")
        print("\nä¸»è¦æ”¹è¿›:")
        print("1. æ”¯æŒæ‰€æœ‰ä¸»è¦LLMæœåŠ¡çš„å®Œæ•´å‚æ•°åˆ—è¡¨")
        print("2. é…ç½®æ–‡ä»¶åŒ…å«è¯¦ç»†çš„å‚æ•°è¯´æ˜")
        print("3. å®¢æˆ·ç«¯å®ç°æ”¯æŒæ–°å‚æ•°ä¼ é€’")
        print("4. Mockå®¢æˆ·ç«¯æ”¯æŒå‚æ•°æ¨¡æ‹Ÿ")
        
        return 0
    else:
        print("âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥")
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main())