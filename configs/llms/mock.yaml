# Mock LLM 配置（用于测试）
model_type: mock
model_name: mock-model

parameters:
  # 基础生成参数
  temperature: 0.7
  max_tokens: 2000
  max_completion_tokens: null
  top_p: 1.0
  top_k: 40
  
  # 惩罚参数
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # 停止序列
  stop: null
  stop_sequences: null
  
  # 采样和概率参数
  top_logprobs: null
  
  # 工具调用参数
  tool_choice: null
  tools: null
  
  # 响应格式
  response_format: null
  response_mime_type: null
  
  # 流式和控制参数
  stream: false
  stream_options: null
  
  # 服务和安全参数
  service_tier: "auto"
  safety_identifier: null
  store: false
  
  # 推理参数
  reasoning: null
  thinking_config: null
  
  # 详细程度控制
  verbosity: "medium"
  
  # 网络搜索选项
  web_search_options: null
  
  # 其他参数
  seed: null
  user: null
  system: null
  system_instruction: null
  candidate_count: 1
  safety_settings: null
  metadata: null
  
  # 连接参数
  timeout: 1
  max_retries: 3

# Mock特定配置
response_delay: 0.1  # 响应延迟（秒）
error_rate: 0.0  # 错误率（0-1）
error_types:  # 可能的错误类型
  - timeout
  - rate_limit

# 降级配置
fallback_enabled: false
fallback_models: []
max_fallback_attempts: 0

# 元数据
metadata:
  provider: mock
  version: "1.0"
  description: "Mock LLM 模型，用于测试"