# Mock LLM 配置（用于测试）
model_type: mock
model_name: mock-model

parameters:
  temperature: 0.7
  max_tokens: 2000
  timeout: 1
  max_retries: 3
  stream: false

# Mock特定配置
response_delay: 0.1  # 响应延迟（秒）
error_rate: 0.0  # 错误率（0-1）
error_types:  # 可能的错误类型
  - timeout
  - rate_limit

# 降级配置
fallback_enabled: false
fallback_models: []
max_fallback_attempts: 0

# 元数据
metadata:
  provider: mock
  version: "1.0"
  description: "Mock LLM 模型，用于测试"